# 创建PXC集群

centos7.0 pxc5.7

* MariaDB
* Percona

MobaXterm链接工具

## 安装PerconaServer数据库

* [安装说明文档](https://www.percona.com/doc/percona-server/5.7/installation/apt_repo.html)

* `apt-get install mysql-client`

* `ufw disable`

* 配置

  ````
  # /etc/mysql/percona-server.conf.d/mysqld.cnf
  character_set_server=utf8
  bind-address=0.0.0.0
  # 跳过DNS解析
  skip-name-resolve
  ````

* `service mysql restart`

* `chkconfig mysqld off` 防止宕机后重启的自动同步

* `systemctl disable mysql` 在ubuntu下

长时间宕机后应该拷贝数据库文件后启动

* `create user 'admin'@'%' identified by '123456';`
* `grant all privileges ON *.* To 'admin'@'%';`
* `flush privileges;`

## 安装PXC组建集群

* 节点配置应该相同
* 需要开放的端口
  * 3306 MySQL服务端口
  * 4444 请求全量同步(SST)端口，引发集群限速
  * 4567 数据库之间通信端口
  * 4568 请求增量同步(IST端口)
* [安装文档](https://www.percona.com/doc/percona-xtradb-cluster/5.7/install/apt.html#apt)

````
wget https://repo.percona.com/apt/percona-release_latest.$(lsb_release -sc)_all.deb
sudo dpkg -i percona-release_latest.$(lsb_release -sc)_all.deb
sudo apt-get update
````

* `service mysql stop` 停止mysql防止同步

````
node1 192.168.232.167
node2 192.168.232.168
node3 192.168.232.169
````

````
# /etc/mysql/percona-xtradb-cluster.conf.d/wsrep.cnf
server-id=3  #PXC集群中MySQL实例的唯一ID，不能重复，必须是数字
wsrep_provider=/usr/lib/galera3/libgalera_smm.so
wsrep_cluster_name=pxc-cluster  #PXC集群的名称
wsrep_cluster_address=gcomm://192.168.232.167,192.168.232.168,192.168.232.169
wsrep_node_name=pxc3  #当前节点的名称
wsrep_node_address=192.168.232.169  #当前节点的IP
wsrep_sst_method=xtrabackup-v2  #同步方法（mysqldump、rsync、xtrabackup）
wsrep_sst_auth= admin:123456  #同步使用的帐户
pxc_strict_mode=ENFORCING  #同步严厉模式
binlog_format=ROW  #基于ROW复制（安全可靠）
default_storage_engine=InnoDB  #默认引擎
innodb_autoinc_lock_mode=2  #主键自增长不锁表
````

* `/etc/init.d/mysql bootstrap-pxc` 首节点启动
* `service mysql start` 首节点启动数据库
* `service mysql start` 启动其他节点

## PXC集群的常用管理-数据库集群使用

### 同步信息

* `show status like 'wsrep_cluster%';` 查看集群节点信息
  * `show status like '%wsrep%';`
    * `wsrep_last_applied` 同步应用的次数
    * `wsrep_last_committed` 事务提交次数
    * `wsrep_replicated` 被其他节点复制的总数
    * `wsrep_replicated_bytes` 被其他节点复制的数据总数
    * `wsrep_received` 从其他节点处收到的总请求总数
    * `wsrep_received_bytes` 从其他节点处收到的数据总数

### 队列信息

* `wsrep_local_send_queue` 发送队列的长度
* `wsrep_local_send_queue_max` 发送队列的最大长度
* `wsrep_local_send_queue_min` 发送队列的最小长度
* `wsrep_local_send_queue_avg` 发送队列的平均长度，第一个参数和这个同时很大说明效率用问题
* `wsrep_local_recv_queue` 接收队列的长度
* `wsrep_local_recv_queue_max` 接收队列的最大长度
* `wsrep_local_recv_queue_min` 接收队列的最小长度
* `wsrep_local_recv_queue_avg` 接收队列的平均长度

### 流量控制

例如：节点添加会引发，应该拷贝数据文件

* `wsrep_flow_control_paused_ns` 流控暂停状态下花费的总时间
* `wsrep_flow_control_paused` 流量控制暂停时间的占比（0~1），越大流控占比越多
* `wsrep_flow_control_sent` 发送的流控暂停事件的数量
* `wsrep_flow_control_recv` 接受的流控暂停事件的数量
* `wsrep_flow_control_interval` 流量控制的下限和上限。上限 是队列中允许的最大请求数。如果队列达到上限，则会拒绝新的请求。当处理现有请求时，队列会减少，一旦达到下限，将再次运行新的请求
* `wsrep_flow_control_status` 流量控制的状态

解决方案：

* 提高网络环境
* 增加线程
  * `wsrep_slave_threads=16` 线程数量，CPU线程数的1~1.5倍

## PXC集群的常用管理-状态参数

### 状态参数

* `wsrep_local_state_comment` 节点状态
* `wsrep_cluster_staus` 集群状态（PRIMARY、NON_PRIMARY、Disconnected）
* `wsrep_connected` 节点是否链接到集群
* `wsrep_ready` 集群是否正常工作
* `wsrep_cluster_size` 节点数量
* `wsrep_desync_count` 延时节点数量
* `wsrep_incoming_addresses` 集群节点IP

### 事务相关

* `wsrep_cert_deps_distance` 事务并发数
* `wsrep_apply_oooe` 接收队列中事务占比
* `wsrep_apply_oool` 接收队列中事务乱序执行的频率
* `wsrep_apply_window` 接收队列中事务的平均数量
* `wsrep_commit_oooe` 发送队列中事务的占比
* `wsrep_commit_oool` 无任何意义

## PXC节点的上线与关闭

节点如何启动就如何关闭

* `/var/lib/mysql/grastate.dat` 当safe_to_bootstrap为1时作为主节点
* `/etc/init.d/mysql stop` 关闭主节点

启动时要先启动为1时

若全部为0，先修改一个为1后启动

## MySQL集群中间件比较

* 负载均衡类
  * 负载均衡提供了请求转发，降低了单节点的负载
  * Haproxy
  * MySQL-Proxy
* 数据切分类
  * 按照不同的路由算法分发SQL语句形成数据切分，防止单表2000万的问题，将一个集群当作一个分片，分片上使用中间件，注意冷热数据，冷数据不占用分片进入到归档数据库
  * MyCat 
  * Atlas
  * OneProxy
  * ProxySQL

## 配置MyCat负载均衡

* `sudo apt-get install -y openjdk-8-jre`
* `sudo apt-get install -y openjdk-8-jkd`

```
# /etc/profile
#set jdk environment 
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export JRE_HOME=$JAVA_HOME/jre 
export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH 
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 
```

- `source /etc/profile `
- `[http://www.mycat.io](http://www.mycat.io/)` 下载地址

`````
mycat/
├── bin # 命令
├── catlet
├── conf # 配置文件
│   ├── rule.xml # 切分算法，将mod-log修改为分片数量
│   ├── server.xml # 虚拟MySQL，修改用户名，密码和逻辑库
│   ├── schema.xml # 数据库连接，读写分离，负载均衡，数据表映射
├── lib
├── logs # 日志
└── version.txt
`````

`````xml
<!-- server.xml -->
	<user name="admin" defaultAccount="true">
		<property name="password">123456</property>
		<property name="schemas">user</property> <!-- 数据库 -->
		
		<!-- 表级 DML 权限设置 -->
		<!-- 		
		<privileges check="false">
			<schema name="TESTDB" dml="0110" >
				<table name="tb01" dml="0000"></table>
				<table name="tb02" dml="1111"></table>
			</schema>
		</privileges>		
		 -->
	</user>


<!-- 只读用户，非必须 -->
<!-- 	<user name="user">
		<property name="password">user</property>
		<property name="schemas">TESTDB</property>
		<property name="readOnly">true</property>
	</user>
 -->

`````

````xml
<!-- schema.xml -->
<!-- 定义虚拟的逻辑库及虚拟的逻辑表 -->
<schema name="test" checkSQLschema="false" sqlMaxLimit="100"> <!-- 定义虚拟的逻辑库 -->
		<table name="t_user" dataNode="dn1,dn2,dn3" rule="mod-long" /> <!-- 定义虚拟的逻辑表,dataNode:分片，rule:切分算法 -->
</schema>


<!-- name:分片的名称，dataHost:对应下面dataHost的name, databas:被操作的数据库-->
<dataNode name="dn1" dataHost="mycat1" database="db1" /> <!-- 定义的分片 -->
<dataNode name="dn2" dataHost="mycat2" database="db1" /> <!-- 定义的分片 -->

<!-- 数据库的连接信息 -->
	<!-- name:自定义一连接信息名称 maxCon minCon 数据库连接池信息 balance：负载均衡类型，0表示不开启读写分离，为1读写分离，为2每个节点同时负责读写，writeType：0表示所有写请求分发给第一个写节点，1表示写操作由所有写节点操作，switchType：切换节点的的依据，1使用mycat自己的心跳检测，用数据库集群的信息判断 -->
	<dataHost name="mycat1" maxCon="1000" minCon="10" balance="2"
			  writeType="1" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
		<heartbeat>select user()</heartbeat> <!-- 心跳检测的sql语句 -->
		<writeHost host="pxc1" url="192.168.232.167:3306" user="admin"
				   password="123456"> <!-- 配置写节点 -->
			<readHost host="pxc2" url="192.168.232.168:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
          	<readHost host="pxc3" url="192.168.232.169:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
		</writeHost>
      <!-- 一个冗余设计 -->
		<writeHost host="pxc2" url="192.168.232.168:3306" user="admin"
				   password="123456"> <!-- 配置写节点 -->
			<readHost host="pxc1" url="192.168.232.167:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
          	<readHost host="pxc3" url="192.168.232.169:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
		</writeHost>
	</dataHost>

<!-- 另外一个分片 -->
	<dataHost name="mycat2" maxCon="1000" minCon="10" balance="2"
			  writeType="1" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
		<heartbeat>select user()</heartbeat> <!-- 心跳检测的sql语句 -->
		<writeHost host="pxc1" url="192.168.232.167:3306" user="admin"
				   password="123456"> <!-- 配置写节点 -->
			<readHost host="pxc2" url="192.168.232.168:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
          	<readHost host="pxc3" url="192.168.232.169:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
		</writeHost>
      <!-- 一个冗余设计 -->
		<writeHost host="pxc2" url="192.168.232.168:3306" user="admin"
				   password="123456"> <!-- 配置写节点 -->
			<readHost host="pxc1" url="192.168.232.167:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
          	<readHost host="pxc3" url="192.168.232.169:3306" user="admin" password="123456" /> <!-- 配置读节点 -->
		</writeHost>
	</dataHost>
````

`````xml
# rule.xml
<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
  <!-- how many data nodes -->
  <property name="count">2</property> <!-- 对应你的分片数量 -->
</function>
`````

* `8066` 数据服务接口，也即数据读写连接端口
* `9066` 管理端口
* `cd bin && chomd -R 777 ./*.sh`
* `./startup_nowrap.sh`
* 杀死进程即关闭

## 数据切分

| 切分算法   | 适用场合           | 备注     |
| ------ | -------------- | ------ |
| 主键求模切分 | 数据增长速度慢，难于增加分片 | 有明确主键值 |
| 枚举值切分  | 归类存储数据，适合大多数业务 |        |
| 主键范围切分 | 数据快速增长，容易增加分片  | 有明确主键值 |
| 日期切分   | 数据快速增长，容易增加分片  |        |

### 主键求模切分

* 球磨切分适合数据量大，但数据增长不快的场景，地图产品、行政数据、企业数据
* 扩展分片难度大，迁移数据量大

### 枚举值切分

* 按照某字段的值（数字）来切分数据，用来归类数据

````xml
	<tableRule name="sharding-by-intfile"><!-- 名称可以自由修改 -->
		<rule>
			<columns>sharding_id</columns> <!-- 数据表中特定的字段名称 -->
			<algorithm>hash-int</algorithm> <!-- 对应的底层算法 -->
		</rule>
	</tableRule>
````

````
# /mycat/conf/customer-hash-init.txt
101=0
102=0
103=0
104=1
105=1
101=1
````

````xml
<tableRule name="sharding-by-intfile">
  <rule>	
  	<columns>sharding_id</columns>
  	<algorithm>hash-int</algorithm>
  </rule>
</tableRule>

<tableRule name="sharding-customer">
  <rule>
  	<columns>sharding_id</columns> <!-- 指定的字段 -->
  	<algorithm>customer-hash-int</algorithm>
  </rule>
</tableRule>

.....
<function name="hash-int"
		class="io.mycat.route.function.PartitionByFileMap">
		<property name="mapFile">partition-hash-int.txt</property>
</function>
<function name="customer-hash-int"
		class="io.mycat.route.function.PartitionByFileMap">
		<property name="mapFile">customer-hash-init.txt</property>
</function>
````

* `mysql$:reload @@config_all;` 重新热加载

### 主键范围切分

### 日期切分

## 父子表

在MyCat中不允许跨分片做表连接查询

父子表：对父表进行切分对子表不允许切分

````xml
<!-- schema.xml -->
<schema name="test" checkSQLschema='false' sqlMaxLimit="100">
    <table name="t_customer" dataNode="dn1,dn2" rule="sharding-customer">
        <childTable name="t_orders" primaryKey="ID" joinKey="customer_id"   
                    parentKey="id"/> <!-- primaryKey:非必须，joinKey子表字段，parentKey父表字段，子表可以包含字表，也可以有多个字表 -->
    </table>
</schema>
````

## 组建双机热备的MyCat集群-构建高可用的MyCat集群









## 组建双机热备的MyCat集群-利用keepalived抢占虚拟IP

## Sysbench基准测试-安装Sysbench

## Sysbench基准测试-使用Sysbench

## tpcc-mysql压力测试







