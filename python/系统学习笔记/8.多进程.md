# 多进程

**调度算法方式**

* 时间片轮转
* 优先级调度

**概念**

* 并发 任务有部分被执行
* 并行 任务都被执行

## 进程

* 编码完毕在没运行时是程序
* 当程序运行并拥有的资源环境叫进程

## fork(子进程)

```python
# windows不支持
import os 
import time

ret = os.fork()
if ret == 0: # 子进程
    while True:
        print('--1--')
        time.sleep(3)
else:	#主（父）进程
    while True:
        print('--2--')
        time.sleep(3)
```

## getpid、getppid()

* `getpid()` 进程id
* `gitppid()` 父进程id

```python
import os
import time

ret = os.fork()
print('main')	#父子进程都执行

if ret > 0:
    print('--父进程--%d'%os.getpid())
else:
    print('--子进程--%d--%d'%(os.getpid(), os.getppid()))
```

##主进程子进程结束

```python
import os 
import time

ret = os.fork()
if ret == 0:
    print('---子进程---start')
    time.sleep(5)
    print('---子进程---end')
else:
    print('----父进程---start')
    time.sleep(3)
    print('---父进程---end')

print('----over----')
```

进程退出彼此没有关系

## 变量共享

父进程和子进程之间变量不共享

```python
import os
import time

g_num = 100

ret = os.fork()
if ret==0:
    print("子进程")
    g_num += 1
    print('g_num = %d' % g_num)	
else:
    time.sleep(3)
    print('父进程')
    print('g_num = %d ==' % g_num)
```

## 多个fork

```python
import os
import time

g_num = 100

ret = os.fork()
if ret==0:
    print('---1---')
else:
    print('---2---')


ret = os.fork()
if ret==0:
    print('---1---')
else:
    print('---2---')
    
'''
---2---
---1---
---2---
---2---
---1---
---1---
'''
```

多个fork时，会将父fork会接着执行子fork

**fork炸弹**

```python
import os
while True:
    os.fork()
```

## multiprocessing

### process([group [, target [, name [, args [, kwargs]]]]])

- target：表示这个进程实例所调用对象；
- args：表示调用对象的位置参数元组；
- kwargs：表示调用对象的关键字参数字典；
- name：为当前进程实例的别名；
- group：大多数情况下用不到；

类常用方法：

- is_alive()：判断进程实例是否还在执行；
- join([timeout])：是否等待进程实例执行结束，或等待多少秒；
- start()：启动进程实例（创建子进程）；
- run()：如果没有给定target参数，对这个对象调用start()方法时，就将执行对象中的run()方法；
- terminate()：不管任务是否完成，立即终止；

类常用属性：

- name：当前进程实例别名，默认为Process-N，N为从1开始递增的整数；
- pid：当前进程实例的PID值；

```python
from multiprocessing import Process
import time

def test():
    while True:
        print("---test---")
        time.sleep(1)

p = Process(target=test) # target指定执行的代码
p.start() #新进程开始执行

while True:
    print('---main---')
    time.sleep(1)
```

此时主进程并不会因为执行完成后就退出，主进程将等待子进程执行完成后才退出

```python
import time

def test():
    while True:
        print("---test---")
        time.sleep(1)

p = Process(target=test)
p.start()
```

**join()**

子进程使用变量内容不会导致数据脏读

````python
from multiprocessing import Process
import time

num = 0
def test(num):
    while True:
        num += 1
        print('--- test ---')
        print('num = %d' % num)

        if num == 10:
            return
        time.sleep(1)

p = Process(target = test, args = (num,))
p.start()

p.join()	# 只有等子进程结束后才会继续执行

while True:
   print('--- main ---')

````

## process子类

```python
from multiprocessing import Process
import os
import time

class Process_class(Process):
    def __init__(self, interval):
        Process.__init__(self)
        self.interval = interval

    # 重写run方法
    def run(self):
        print("子进程(%s)开始执行，父进程为(%s)" % (os.getpid(), os.getppid()))
        t_start = time.time()
        time.sleep(self.interval) #模拟实际上的代码执行，可以使用可以执行函数
        t_stop = time.time()
        print("(%s)执行结束，耗时%0.2f秒"%(os.getpid(), os.getppid()))


if __name__ == "__main__":
    t_start = time.time()
    print("当前程序进程(%s)"%os.getpid())
    p1 = Process_class(2)
    # 对不包含target属性的Process类执行start()方法，会调用类中的run()
    p1.start()
    p1.join()
    print('子进程结束')
```

## 进程池

```python
from multiprocessing import Pool
import os, time, random

def worker(msg):
    t_start = time.time()
    print("%s开始执行，进程号%d"%(msg, os.getpid()))
    #random.random() 随机生成0~1之间的浮点数
    time.sleep(random.random() * 2)
    t_stop = time.time()
    print(msg, '执行完毕，耗时%0.2f'%(t_stop - t_start))

po = Pool(3) #定义进程池，最大进程数为3

for i in range(0, 10):
    # apply_async(要调用的目标, (传递给目标的参数元组))
    # 每次循环将会空闲出来的子进程去调用目标
    po.apply_async(worker, (i,)) # 非堵塞的方式

# 主进程不会主动等待子进程结束
print('---start---')
po.close() # 关闭进程池，关闭后po不再接受新的请求
po.join() # 等待po中所有子进程执行完成，必须放在close语句之后
print('---end---')
```

进程pid只有三个，任务会以一种队列的形式依次执行

## 堵塞方式

```python
po.apply(worker, (i,)) # 堵塞的方式,将等待上一进程完成后添加任务
```

## 进程间通信(Queue)

先进先出

* Queue.put(item, [block[, timeout]]) 将item消息写入队列，block默认为True
* Queue.full() 如果队列满了，返回True，反正返回False
* Queue.get([block, [,timeout]]) 获取队列中的一条消息，然后将其从队列中移除，block默认为True
* Queue.get_nowait() 相当于Queue.get(False)
* Queue.put(item, [block[, timeout]]) 将item消息写入队列，block默认值为True
* Queue.qsize() 反回当前队列消息数量
* Queue.empty() 如果队列为空，返回True，反之返回False
* Queue.put_nowait(item) 相当于Queue.put(item, False)

### 使用process形式

```python
from multiprocessing import Queue, Process
import os, time, random

# 写数据进程执行的代码
def write(q):
    for val in ['A', 'B', 'C']:
        print('put %s to queue....' % val)
        q.put(val)
        time.sleep(random.random())

# 读数据进程执行代码
def read(q):
    while True:
        if not q.empty():
            val = q.get(True)
            print('Get %s from queue' % val)
            time.sleep(random.random())
        else:
            break 

if __name__ == '__main__':
    # 父进程创建Queue,并传递给子进程
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q, ))

    # 启动写子进程，写入
    pw.start()
    pw.join() # 等待结束

    print('----')

    # 启动读子进程
    pr.start()
    pr.join()
```

### 进程池使用进程间通信

```python
from multiprocessing import Manager,Pool
import os, time, random

def reader(q):
    print("reader启动(%s), 父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in range(q.qsize()):
        print("reader从Queue中获取消息:%s"%q.get(True))


def writer(q):
    print("write启动(%s),父进程(%s)"%(os.getpid(), os.getppid()))
    for i in "dongGe":
        q.put(i)

if __name__ == "__main__":
    print("%s start" % os.getpid())
    q = Manager().Queue() #使用Manager中的Queue来初始化
    po=Pool()

    #使用阻塞模式
    po.apply(writer, (q,))
    po.apply(reader, (q,))

    po.close()
    po.join()
    print("(%s) End" % os.getpid())
```

### 文件拷贝

```python
from multiprocessing import Pool,Manager
import os,time

def copyFileTask(name, oldFolderName, newFolderName, queue):
    "完成copy一个文件的功能"
    o_fileName = oldFolderName+ '/' + name
    n_filename = newFolderName+ '/' + name

    fr = open(o_fileName, "r")
    fw = open(n_filename, "w")

    content = fr.read()
    fw.write(content)

    fr.close()
    fw.close()

    queue.put(n_filename)
    time.sleep(0.1)

def main():
    # 0. 获取被拷贝文件夹的名字
    oldFolderName = input("请输入您期望拷贝的文件夹名称：")

    # 1. 创建一个新的文件夹
    newFolderName = oldFolderName + '_copy'
    os.mkdir(newFolderName)

    # 2. 获得old文件夹中所有文件的名字
    fileList = os.listdir(oldFolderName)
    #print(fileList)

    # 3. 使用多进程的方式Copy 原文件夹中的所有文件到新的文件夹
    pool = Pool(5)
    queue = Manager().Queue()

    for name in fileList:
        pool.apply_async(copyFileTask, args=(name, oldFolderName, newFolderName, queue))

    num = 0
    all_num = len(fileList)
    print(all_num)
    while num < all_num:
        queue.get()
        num += 1
        print(num)
        copyRate = num/all_num

        #print("\rcopy的进度是：%.2f%%" % (copyRate*100), end="")
        time.sleep(0.3)

    # pool.close()
    # pool.join() #等待进程池  任务执行完毕

 
if __name__ == "__main__":
    main()
```

## 并发文件写入

### 文件锁

````python
# -*- coding:utf-8 -*-
import multiprocessing
import random
import fcntl # linux才有

__Author__ = "xinneirong"
__Email__ = "xinneirong@gmail.com"
__Time__ = "2019/5/11 11:14"

def create_phone():
    second = [3, 4, 5, 7, 8][random.randint(0, 4)]
    third = {
        3: random.randint(0, 9),
        4: [5, 7, 9][random.randint(0, 2)],
        5: [i for i in range(10) if i != 4][random.randint(0, 8)],
        7: [i for i in range(10) if i not in [4, 9]][random.randint(0, 7)],
        8: random.randint(0, 9),
    }[second]

    suffix = random.randint(9999999,100000000)
    phone = "1{}{}{}".format(second, third, suffix)

    with open('./phone.txt', 'a+') as phone_handle:
        fcntl.flock(phone_handle.fileno(), fcntl.LOCK_EX)  # 加锁
        phone_handle.write(phone+'|')

if __name__ == '__main__':
    pool = multiprocessing.Pool(3)

    for i in range(500000000):
        pool.apply_async(create_phone)
        print(i)
    pool.close()
    pool.join()
    print("--完成--")
````

