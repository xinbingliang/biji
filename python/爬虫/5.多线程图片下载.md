# 多线程图片下载

## 基础图片下载

```python
# -*- coding:utf8 -*-
import requests
import urllib
import os

def _download_image(url, folder='image'):
    if not os.path.isdir(folder):
        os.mkdir(folder)
    print('downloading %s' % url)

    def _fname(s):
        return os.path.join(folder, os.path.split(url)[1])

    urllib.urlretrieve(url, _fname(url))

def download_wallpaper():
    url = 'http://image.baidu.com/data/imgs'
    params = {
        'pn': 1,
        'rn': 20,
        'col': '壁纸',
        'tag': '国家地理',
        'tag3': '',
        'width': 1600,
        'height': 900,
        'ic': 0,
        'ie': 'utf8',
        'oe': 'utf-8',
        'image_id': '',
        'fr': 'channel',
        'p': 'channel',
        'from': 1,
        'app': 'img.browse.channel.wallpaper',
        't': '0.016929891658946872'
    }
    r = requests.get(url, params=params)
    imgs = r.json()['imgs']
    print('totally %d images' % len(imgs))
    for i in imgs:
        if 'downloadUrl' in i:
            _download_image(i['downloadUrl'])

if __name__ == '__main__':
    download_wallpaper()


```

## 线程图片下载

```python
# -*- coding:utf8 -*-
import requests
import urllib
import os
import threading

gImageList = []     # 图片链接列表，相当于金库
gCondition = threading.Condition()  #线程间同步机制

# 定义生成者
class Producer(threading.Thread):
    def run(self):
        global gImageList
        global gCondition

        print('%s: strted' % threading.current_thread())

        imgs = download_wallpaper_list()
        gCondition.acquire() # 锁上存数据
        for i in imgs:
            if 'downloadUrl' in i:
                gImageList.append(i['downloadUrl'])
        print('%s: produce finished.Left:%s' % (threading.current_thread(), len(gImageList)))
        gCondition.notify_all() #通知消费者
        gCondition.release() #释放锁

# 定义消费者
class Consumer(threading.Thread):
    def run(self):
        print('%s: strted' % threading.current_thread())
        while True:
            global gImageList
            global gCondition
            gCondition.acquire()
            print('%s: trying to download from pool.pool size is %d' % (threading.current_thread(), len(gImageList)) )
            while len(gImageList) == 0:
                gCondition.wait()
                print('%s: waken up.pool size is %d' % (threading.current_thread(), len(gImageList)))
            url = gImageList.pop()
            gCondition.release()
            _download_image(url)

def _download_image(url, folder='image'):
    if not os.path.isdir(folder):
        os.mkdir(folder)
    print('downloading %s' % url)

    def _fname(s):
        return os.path.join(folder, os.path.split(url)[1])

    urllib.urlretrieve(url, _fname(url))

def download_wallpaper_list():
    url = 'http://image.baidu.com/data/imgs'
    params = {
        'pn': 1,
        'rn': 20,
        'col': '壁纸',
        'tag': '国家地理',
        'tag3': '',
        'width': 1600,
        'height': 900,
        'ic': 0,
        'ie': 'utf8',
        'oe': 'utf-8',
        'image_id': '',
        'fr': 'channel',
        'p': 'channel',
        'from': 1,
        'app': 'img.browse.channel.wallpaper',
        't': '0.016929891658946872'
    }
    r = requests.get(url, params=params)
    imgs = r.json()['imgs']
    print('%s: totally %d images' % (threading.current_thread(), len(imgs)))
    return imgs

    # for i in imgs:
    #     if 'downloadUrl' in i:
    #         _download_image(i['downloadUrl'])

if __name__ == '__main__':
    Producer().start() # 创建生产者
    for i in range(1):
        Consumer().start() # 创建消费者
```

## 接下去

### 框架

* scrapy 爬虫框架
* beautifulsoup 解析器 xml/html解析
* Selector/Xpath->scrapy 

### 解决并发

* twisted
* gevent

### 分布式爬虫

* 任务队列
* 任务队列与存储结合
* 数据处理