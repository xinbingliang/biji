# 唐诗三百首爬取

## 诗文列表爬取

```python
# -*- coding:utf-8 -*-
import requests
import re
from HTMLParser import HTMLParser

def _attr(attrs, attrname):
    for attr in attrs:
        if attr[0] == attrname:
            return attr[1]
    return None


class PoemParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.tangshi_list = []

        self.in_div = False # 标记位是否在guwencont2内部
        self.in_a = False # 标记是否在需要的a中

        self.pattern = re.compile(r'''
                            (.*?)           # 匹配标题 group(1)
                            \((.*?)\)       # 匹配作者 group(2)
                        ''', re.VERBOSE)

        self.current_poem = {}              # 当前正在解析的内容

    def handle_starttag(self, tag, attrs):
        if tag == 'div' and _attr(attrs, 'class') == 'guwencont2':
            self.in_div = True

        if self.in_div and tag == 'a':
            self.in_a = True
            self.current_poem['url'] = _attr(attrs, 'href')


    def handle_endtag(self, tag):
        if tag == 'div':
            self.in_div = False

        if tag == 'a':
            self.in_a = False

    def handle_data(self, data):
        if self.in_a:
            print(data)
            m = self.pattern.match(data)
            if m:
                self.current_poem['title'] = m.group(1)
                self.current_poem['author'] = m.group(2)
                self.tangshi_list.append(self.current_poem)
                self.current_poem = {}


def retrive_tangshi_300():
    url = 'http://www.gushiwen.org/gushi/tangshi.aspx'
    r = requests.get(url)
    p = PoemParser()
    p.feed(r.content)   #传送数据
    return p.tangshi_list


if __name__ == '__main__':
    l = retrive_tangshi_300()
    print('total %d poems.' % len(l))
    for i in range(len(l)):
        print('标题：%(title)s\t作者：%(author)s\tURL：%(url)s' % (l[i]))
```

## 获取诗文内容

```python
# -*- coding:utf-8 -*-
import requests
import re
from HTMLParser import HTMLParser

import sys
reload(sys)
sys.setdefaultencoding('utf-8')


def _attr(attrs, attrname):
    for attr in attrs:
        if attr[0] == attrname:
            return attr[1]
    return None


class PoemParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.tangshi_list = []

        self.in_div = False # 标记位是否在guwencont2内部
        self.in_a = False # 标记是否在需要的a中

        self.pattern = re.compile(r'''
                            (.*?)           # 匹配标题 group(1)
                            \((.*?)\)       # 匹配作者 group(2)
                        ''', re.VERBOSE)

        self.current_poem = {}              # 当前正在解析的内容

    def handle_starttag(self, tag, attrs):
        if tag == 'div' and _attr(attrs, 'class') == 'guwencont2':
            self.in_div = True

        if self.in_div and tag == 'a':
            self.in_a = True
            self.current_poem['url'] = _attr(attrs, 'href')


    def handle_endtag(self, tag):
        if tag == 'div':
            self.in_div = False

        if tag == 'a':
            self.in_a = False

    def handle_data(self, data):
        if self.in_a:
            # print(data)
            m = self.pattern.match(data)
            if m:
                self.current_poem['title'] = m.group(1)
                self.current_poem['author'] = m.group(2)
                self.tangshi_list.append(self.current_poem)
                self.current_poem = {}


class PoemContentParser(HTMLParser):
    def __init__(self):
        HTMLParser.__init__(self)
        self.content = []
        self.in_p = False

    def handle_starttag(self, tag, attrs):
        if tag == 'p' and _attr(attrs, 'align') == 'center':
            self.in_p = True

    def handle_endtag(self, tag):
        if tag == 'p':
            self.in_p = False

    def handle_data(self, data):
        if self.in_p:
            self.content.append(data)


def retrive_tangshi_300():
    url = 'http://www.gushiwen.org/gushi/tangshi.aspx'
    r = requests.get(url)
    p = PoemParser()
    p.feed(r.content)   #传送数据
    return p.tangshi_list


def download_poem(poem):
    url = 'http://www.gushiwen.org'+poem['url']
    r = requests.get(url)
    parser = PoemContentParser()
    parser.feed(r.content)
    poem['content'] = '\n'.join(parser.content)

# 格式换行
def trim_ws(s):
    s = re.sub(r'\s+', '', s)

    def _add_crlf(m):
        return m.group() + '\n'

    s = re.sub(r'，|。', _add_crlf, s)
    # s = s.replace('，', '，\n')
    # s = s.replace('。', '。\n')
    return s


# 去除文中特殊的标签
def trim_href(s):
    s = s.replace('<br>', '')
    alt = re.search(r'\s+alt\s*=\s*\"?(.*?)\"\s+', s)
    s = re.sub(r'<a.*</a>', alt.group(1), s)
    return trim_ws(s)


if __name__ == '__main__':
    l = retrive_tangshi_300()
    print('total %d poems.' % len(l))
    # for i in range(len(l)):
    #     print('标题：%(title)s\t作者：%(author)s\tURL：%(url)s' % (l[i]))

    for i in range(len(l)):
        print('#%d downloading poem from: %s' % (i, l[i]['url']))
        download_poem(l[i])
        print('标题: %(title)s\t作者：%(author)s\n%(content)s' % (l[i]))
```







